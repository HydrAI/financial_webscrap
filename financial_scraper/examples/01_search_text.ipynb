{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 — Text Search Mode\n",
    "\n",
    "**Goal:** Search DuckDuckGo in **text** mode for broad financial research content (SEC filings, analyst reports, reference material), extract clean text, and save to Parquet.\n",
    "\n",
    "Text mode returns organic web results (articles, PDFs, reports) rather than recent news. It is best suited for:\n",
    "- SEC filings and annual reports\n",
    "- Research papers and whitepapers\n",
    "- Reference/educational financial content\n",
    "- Historical data and analysis\n",
    "\n",
    "> **Tip:** Text search is more rate-limited by DuckDuckGo than news search. For large runs (50+ queries) use `--stealth` and `--use-tor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Make sure the package is installed:\n",
    "\n",
    "```bash\n",
    "cd financial_scraper\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Windows asyncio fix (required before any asyncio.run call)\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "\n",
    "import pandas as pd\n",
    "from financial_scraper import ScraperConfig, ScraperPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a Query File\n",
    "\n",
    "One query per line. Lines starting with `#` are comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_path = Path(\"queries_text_example.txt\")\n",
    "queries_path.write_text(\n",
    "    \"\"\"# Text search — broad financial research\n",
    "SEC 10-K annual report risk factors analysis\n",
    "copper supply chain disruption impact 2025\n",
    "lithium mining production forecast\n",
    "central bank monetary policy inflation outlook\n",
    "renewable energy investment trends global\n",
    "\"\"\"\n",
    ")\n",
    "print(f\"Wrote {queries_path} ({queries_path.stat().st_size} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure and Run\n",
    "\n",
    "Key settings for text search:\n",
    "\n",
    "| Setting | Value | Why |\n",
    "|---------|-------|-----|\n",
    "| `search_type` | `\"text\"` | Organic results — broader, includes reports/PDFs |\n",
    "| `max_results_per_query` | `10` | Moderate — avoids rate limits while getting enough coverage |\n",
    "| `min_word_count` | `150` | Higher threshold filters out stub pages |\n",
    "| `exclude_file` | default | Built-in list blocks social media, paywalls, low-quality sites |\n",
    "| `favor_precision` | `True` | trafilatura precision mode extracts main content only |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"./runs_text_example\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "output_parquet = output_dir / \"text_search_results.parquet\"\n",
    "output_jsonl = output_dir / \"text_search_results.jsonl\"\n",
    "\n",
    "config = ScraperConfig(\n",
    "    queries_file=queries_path,\n",
    "    search_type=\"text\",\n",
    "    max_results_per_query=10,\n",
    "    min_word_count=150,\n",
    "    favor_precision=True,\n",
    "    output_dir=output_dir,\n",
    "    output_path=output_parquet,\n",
    "    jsonl_path=output_jsonl,\n",
    "    # Domain exclusion: uses built-in list by default (set exclude_file=None to disable)\n",
    "    exclude_file=Path(\"../config/exclude_domains.txt\"),\n",
    ")\n",
    "\n",
    "print(\"Config ready:\")\n",
    "print(f\"  search_type    = {config.search_type}\")\n",
    "print(f\"  max_results    = {config.max_results_per_query}\")\n",
    "print(f\"  min_words      = {config.min_word_count}\")\n",
    "print(f\"  output         = {config.output_path}\")\n",
    "print(f\"  exclude_file   = {config.exclude_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ScraperPipeline(config)\n",
    "await pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_parquet.exists():\n",
    "    df = pd.read_parquet(output_parquet)\n",
    "    print(f\"Total documents: {len(df)}\")\n",
    "    print(f\"Unique sources:  {df['source'].nunique()}\")\n",
    "    print(f\"Total words:     {df['full_text'].str.split().str.len().sum():,}\")\n",
    "    print(f\"Avg words/doc:   {df['full_text'].str.split().str.len().mean():.0f}\")\n",
    "    print()\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "else:\n",
    "    print(\"No output file — check logs above for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first few rows\n",
    "if output_parquet.exists():\n",
    "    df[[\"company\", \"title\", \"source\", \"date\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top domains by article count\n",
    "if output_parquet.exists():\n",
    "    print(\"Top sources:\")\n",
    "    print(df[\"source\"].value_counts().head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results per query\n",
    "if output_parquet.exists():\n",
    "    print(\"Results per query:\")\n",
    "    print(df[\"company\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview full text of the first document\n",
    "if output_parquet.exists() and len(df) > 0:\n",
    "    row = df.iloc[0]\n",
    "    print(f\"Title:  {row['title']}\")\n",
    "    print(f\"Source: {row['source']}\")\n",
    "    print(f\"Date:   {row['date']}\")\n",
    "    print(f\"Words:  {len(row['full_text'].split())}\")\n",
    "    print(f\"\\n--- First 500 chars ---\\n\")\n",
    "    print(row[\"full_text\"][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CLI Equivalent\n",
    "\n",
    "The same run from the command line:\n",
    "\n",
    "```bash\n",
    "financial-scraper search \\\n",
    "    --queries-file queries_text_example.txt \\\n",
    "    --search-type text \\\n",
    "    --max-results 10 \\\n",
    "    --min-words 150 \\\n",
    "    --output-dir ./runs_text_example \\\n",
    "    --jsonl\n",
    "```\n",
    "\n",
    "Add `--stealth` and `--use-tor` for large runs (50+ queries):\n",
    "\n",
    "```bash\n",
    "financial-scraper search \\\n",
    "    --queries-file queries.txt \\\n",
    "    --search-type text \\\n",
    "    --max-results 10 \\\n",
    "    --stealth --use-tor --resume \\\n",
    "    --output-dir ./runs \\\n",
    "    --jsonl\n",
    "```\n",
    "\n",
    "To disable domain exclusions:\n",
    "\n",
    "```bash\n",
    "financial-scraper search --queries-file queries.txt --search-type text --no-exclude\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete temporary files\n",
    "# queries_path.unlink(missing_ok=True)\n",
    "# import shutil; shutil.rmtree(output_dir, ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
